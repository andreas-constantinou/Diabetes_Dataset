{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data-mining-project\n",
    "\n",
    "Use the \"Run\" button to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Warren Ball\n",
    "sources : https://www.geeksforgeeks.org/how-to-reshape-pandas-series/\n",
    "https://stackoverflow.com/questions/14863125/sklearn-logistic-regression-with-unbalanced-classes\n",
    "https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "okay, let's look at basic characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes_binary.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GenHlth, correlation with diabetes: 0.28769724599353597\n",
      "For HighBP, correlation with diabetes: 0.26312878992336214\n",
      "For BMI, correlation with diabetes: 0.22631421069982066\n",
      "For DiffWalk, correlation with diabetes: 0.21834435192101798\n",
      "For HighChol, correlation with diabetes: 0.20027619187912013\n",
      "For Age, correlation with diabetes: 0.17768426329341755\n",
      "For HeartDiseaseorAttack, correlation with diabetes: 0.1772822578072029\n",
      "For PhysHlth, correlation with diabetes: 0.15675169713222603\n",
      "For Stroke, correlation with diabetes: 0.10581606726811367\n",
      "For CholCheck, correlation with diabetes: 0.06476081015893631\n",
      "For Smoker, correlation with diabetes: 0.06078850564034085\n",
      "For MentHlth, correlation with diabetes: 0.04004895281242356\n",
      "For NoDocbcCost, correlation with diabetes: 0.031432763359259056\n",
      "For Sex, correlation with diabetes: 0.03142999802068085\n",
      "For AnyHealthcare, correlation with diabetes: 0.016255139545865795\n",
      "For Fruits, correlation with diabetes: -0.04077922810406531\n",
      "For Veggies, correlation with diabetes: -0.056584137064162564\n",
      "For HvyAlcoholConsump, correlation with diabetes: -0.057056256121682365\n",
      "For PhysActivity, correlation with diabetes: -0.11813311489591133\n",
      "For Education, correlation with diabetes: -0.12003773605832627\n",
      "For Income, correlation with diabetes: -0.16330469335765088\n"
     ]
    }
   ],
   "source": [
    "# Checking correlation with all features\n",
    "Diabetes = df['Diabetes_binary']\n",
    "#Every single column is in this array\n",
    "column_array = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "all_correlations = []\n",
    "for i in range (len(column_array)):\n",
    "    current_index = df[column_array[i]]\n",
    "    spearmanr_coefficient, p_value = spearmanr(Diabetes, current_index)\n",
    "    all_correlations.append([column_array[i], spearmanr_coefficient])\n",
    "\n",
    "all_correlations.sort(key = lambda all_correlations : all_correlations[1], reverse = True)\n",
    "for i in range(len(all_correlations)):\n",
    "    print(\"For \" + str(all_correlations[i][0]) + ', correlation with diabetes: ' + str(all_correlations[i][1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we'll use Naive Bayes for this\n",
    "let's use every feature with a correlation of .2 and above (or -.2 and below)\n",
    "and get as accurate a model as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note, starting with highest correlation, i kept adding cols until scores get lower\n",
    "#then i stopped\n",
    "df = df[['Diabetes_binary', 'GenHlth', 'HighBP', 'BMI', 'DiffWalk', 'HighChol', 'Age']]\n",
    "\n",
    "x_full, x_test, y_full, y_test = train_test_split(df[['GenHlth', 'HighBP', 'BMI', 'DiffWalk', 'HighChol', 'Age']], df['Diabetes_binary'], test_size = 0.15)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_full, y_full, test_size = 0.15)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "given that we don't care about accuracy as much as accurately predicting those with diabetes\n",
    "we'll set fit_prior to False to make it so the priors are even between diabetes and no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_obj = CategoricalNB(fit_prior=False).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715844798268666\n",
      "[[19688  8141]\n",
      " [ 1050  3466]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     27829\n",
      "         1.0       0.30      0.77      0.43      4516\n",
      "\n",
      "    accuracy                           0.72     32345\n",
      "   macro avg       0.62      0.74      0.62     32345\n",
      "weighted avg       0.86      0.72      0.76     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod_obj.score(x_val, y_val))\n",
    "pred_y = mod_obj.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred_y))\n",
    "print(classification_report(y_val, pred_y))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inherently now that we know what correlates well, let's see if we can transform anything to make it better"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##Beginning of data manipulation\n",
    "##Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn import over_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "x_over, y_over = RandomOverSampler(random_state = 0).fit_resample(x_train, y_train)\n",
    "\n",
    "#okay, with new data, we can use oversampled data to see if it improves naive bayes\n",
    "#also we can stop fit_prior since it doesn't help anymore\n",
    "mod_over_obj = CategoricalNB().fit(x_over, y_over)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "okay, now we see how well it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152264646776936\n",
      "[[19666  8163]\n",
      " [ 1048  3468]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     27829\n",
      "         1.0       0.30      0.77      0.43      4516\n",
      "\n",
      "    accuracy                           0.72     32345\n",
      "   macro avg       0.62      0.74      0.62     32345\n",
      "weighted avg       0.86      0.72      0.76     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod_over_obj.score(x_val, y_val))\n",
    "over_pred_y = mod_over_obj.predict(x_val)\n",
    "print(confusion_matrix(y_val, over_pred_y))\n",
    "print(classification_report(y_val, over_pred_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "well, it doesn't sem to do much, recall is still the same\n",
    "so are FP, FN, TP, and TN more or less"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Begin SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#note i tried a bunch of different k_neighbor. 10 seems to be the best\n",
    "smote_x, smote_y = SMOTE(sampling_strategy = 'minority', k_neighbors = 10).fit_resample(x_train, y_train)\n",
    "mod_obj_smote = CategoricalNB().fit(smote_x, smote_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7107744628226929\n",
      "[[19498  8331]\n",
      " [ 1024  3492]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.70      0.81     27829\n",
      "         1.0       0.30      0.77      0.43      4516\n",
      "\n",
      "    accuracy                           0.71     32345\n",
      "   macro avg       0.62      0.74      0.62     32345\n",
      "weighted avg       0.86      0.71      0.75     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod_obj_smote.score(x_val, y_val))\n",
    "smote_pred_y = mod_obj_smote.predict(x_val)\n",
    "print(confusion_matrix(y_val, smote_pred_y))\n",
    "print(classification_report(y_val, smote_pred_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Interesting. I think it helped with the TN score and recall. So it's slightly better.\n",
    "And it didn't increase False Negatives by that much either."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Begin undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import under_sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "x_under, y_under = RandomUnderSampler(random_state = 0).fit_resample(x_train,y_train)\n",
    "mod_under = CategoricalNB().fit(x_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151646313185964\n",
      "[[19664  8165]\n",
      " [ 1048  3468]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.81     27829\n",
      "         1.0       0.30      0.77      0.43      4516\n",
      "\n",
      "    accuracy                           0.72     32345\n",
      "   macro avg       0.62      0.74      0.62     32345\n",
      "weighted avg       0.86      0.72      0.76     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod_under.score(x_val, y_val))\n",
    "under_pred_y = mod_under.predict(x_val)\n",
    "print(confusion_matrix(y_val, under_pred_y))\n",
    "print(classification_report(y_val, under_pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it doesn't seem like it's much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, our best is SMOTE. At least in terms of TN. so we'll try this for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221171029118049\n",
      "[[23393  9397]\n",
      " [ 1177  4085]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.71      0.82     32790\n",
      "         1.0       0.30      0.78      0.44      5262\n",
      "\n",
      "    accuracy                           0.72     38052\n",
      "   macro avg       0.63      0.74      0.63     38052\n",
      "weighted avg       0.86      0.72      0.76     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod_under.score(x_test, y_test))\n",
    "under_pred_y = mod_under.predict(x_test)\n",
    "print(confusion_matrix(y_test, under_pred_y))\n",
    "print(classification_report(y_test, under_pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, it seems like the SMOTE model actually works slightly better than predicted.\n",
    "With this. I thnk this is the best that naive bayes can offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is what the function would look like without anything done to it. It achieves a high accuracy, but it's at\n",
    "the expense of poorly predicted positive diabetes cases. This is useless for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8341480079890676\n",
      "[[29436  3273]\n",
      " [ 3038  2305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.65      0.74     32709\n",
      "         1.0       0.14      0.36      0.20      5343\n",
      "\n",
      "    accuracy                           0.61     38052\n",
      "   macro avg       0.50      0.50      0.47     38052\n",
      "weighted avg       0.76      0.61      0.66     38052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"diabetes_binary.csv\")\n",
    "\n",
    "# #print(df)\n",
    "\n",
    "df = df[['Diabetes_binary', 'GenHlth', 'HighBP', 'BMI', 'DiffWalk', 'HighChol', 'Age']]\n",
    "\n",
    "\n",
    "\n",
    "x_full, x_test, y_full, y_test = train_test_split(df[['GenHlth', 'HighBP', 'BMI', 'DiffWalk', 'HighChol', 'Age']], df['Diabetes_binary'], test_size = 0.15)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_full, y_full, test_size = 0.15)\n",
    "\n",
    "ret_obj = CategoricalNB().fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(ret_obj.score(x_test, y_test))\n",
    "\n",
    "pred_y = ret_obj.predict(x_test)\n",
    "print(confusion_matrix(y_test, pred_y))\n",
    "print(classification_report(y_test, under_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
